{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f70a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random\n",
    "# Fix the number for repeatability (we have also stored the trained model)\n",
    "numpy.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ac8f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ebac0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.misc\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd  import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.inception import inception_v3\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def zero_gradients(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        if x.grad is not None:\n",
    "            x.grad.detach_()\n",
    "            x.grad.zero_()\n",
    "    elif isinstance(x, collections.abc.Iterable):\n",
    "        for elem in x:\n",
    "            zero_gradients(elem)        \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c266495",
   "metadata": {},
   "source": [
    "# MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb2e53ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "sizeOfNeuronsToMonitor = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8590fe7e",
   "metadata": {},
   "source": [
    "### 1- Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3907dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz to data/mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data/mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data/mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data/mnist\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='data/mnist', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='data/mnist', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899bf40e",
   "metadata": {},
   "source": [
    "### 2- Model ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a554cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    " \n",
    "        self.conv1 = nn.Conv2d(1, 40, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(40, 20, 5)\n",
    "        self.fc1 = nn.Linear(20 * 4 * 4, 160)\n",
    "        self.fc2 = nn.Linear(160, 80)\n",
    "        self.fc3 = nn.Linear(80, sizeOfNeuronsToMonitor)\n",
    "        self.fc4 = nn.Linear(sizeOfNeuronsToMonitor, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Original 28x28x1 -(conv)-> 24x24x40 -(pool)-> 12x12x40\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # Original 12x12x40 -(conv)-> 8x8x20 -(pool)-> 4x4x20\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Flatten it to an array of inputs\n",
    "        x = x.view(-1, 20 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        out = self.fc4(x)\n",
    "        return out \n",
    "  \n",
    "    # Here we add another function, which does the same forward computation but also extracts intermediate layer results\n",
    "    def forwardWithIntermediate(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 20 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        intermediateValues = x\n",
    "        x = F.relu(x)\n",
    "        out = self.fc4(x)\n",
    "        return out, intermediateValues    \n",
    "    \n",
    "net = NeuralNet()\n",
    "net.eval()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7110e4",
   "metadata": {},
   "source": [
    "### 3- Load the model (if you have a pretrained one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4c2c60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('models/1_model_MNIST_CNN.ckpt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6664fbd2",
   "metadata": {},
   "source": [
    "### 4- Compute accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac8b317b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.81 %\n"
     ]
    }
   ],
   "source": [
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    outofActivationPattern = 0\n",
    "    outofActivationPatternAndResultWrong = 0\n",
    "    \n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f68d7a",
   "metadata": {},
   "source": [
    "# Runtime Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6de1cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from napmonitor import *\n",
    "monitor = NAP_Monitor(num_classes, sizeOfNeuronsToMonitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4398dcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the all train images: 99.34166666666667 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        labels = labels.to(device)\n",
    "        outputs, intermediateValues = net.forwardWithIntermediate(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Add the batch of neuron activation patterns to the monitor\n",
    "        monitor.addAllNeuronPatternsToClass(intermediateValues.numpy(), predicted.numpy(), labels.numpy(), -1)\n",
    "\n",
    "                \n",
    "    print('Accuracy of the network on the all train images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "744bcb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Operational Data:  2000\n",
      "Number of Operational Data correctly predicted by the model :  1965\n",
      "Number of Operational Data wrong predicted by the model :  35\n",
      "Accuracy of the Model on Operational Data: 98.25 %\n",
      "Number of Operatioanl Data Decided as incorrect by the monitor:  1815\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    outofActivationPattern = 0\n",
    "    outofActivationPatternAndResultWrong = 0\n",
    "    \n",
    "    total = 0\n",
    "    \n",
    "    nbIter = 0\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        \n",
    "        labels = labels.to(device)\n",
    "        outputs, intermediateValues = net.forwardWithIntermediate(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "                \n",
    "        # Additional processing for runtime monitoring\n",
    "        \n",
    "        predictedNp = predicted.numpy()\n",
    "        \n",
    "        result = (predicted == labels)\n",
    "        res = result.numpy()\n",
    "               \n",
    "        # Iterate over each image in the batch\n",
    "        for exampleIndex in range(intermediateValues.shape[0]):   \n",
    "            if not monitor.isPatternContained(intermediateValues.numpy()[exampleIndex,:], predicted.numpy()[exampleIndex]):\n",
    "                outofActivationPattern = outofActivationPattern +1\n",
    "                if res[exampleIndex] == False :\n",
    "                    outofActivationPatternAndResultWrong = outofActivationPatternAndResultWrong + 1\n",
    "        \n",
    "        nbIter = nbIter + 1\n",
    "        if(nbIter == 2000):\n",
    "            break\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Total number of Operational Data: ', nbIter)\n",
    "\n",
    "    print('Number of Operational Data correctly predicted by the model : ', correct)\n",
    "\n",
    "    print('Number of Operational Data wrong predicted by the model : ', total - correct)\n",
    "\n",
    "    print('Accuracy of the Model on Operational Data: {} %'.format(100 * correct / total))\n",
    "\n",
    "    print('Number of Operatioanl Data Decided as incorrect by the monitor: ', total - outofActivationPattern+outofActivationPatternAndResultWrong)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48acf07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
